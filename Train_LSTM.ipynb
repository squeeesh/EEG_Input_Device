{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "240ce4fa-9879-46d5-a776-264a732fd0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Squish\\projects\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "z = os.path.abspath(\"\")\n",
    "y = os.getcwd()\n",
    "print(y)\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data.sampler import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49c3804d-25c8-465c-aff6-aa0a126482c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eeg_and_keystroke_data.csv')\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        x = data[i:(i+seq_length), :-1]  # All columns except the last one are features\n",
    "        y = data[i+seq_length-1, -1]  # The last column is the target\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def replace_value(data):\n",
    "    for i in range(1, len(data)):\n",
    "        print(data)\n",
    "        print(typeof(data))\n",
    "        a = data[i]\n",
    "        print(a)\n",
    "        print(typeof(a))\n",
    "        if a is not None:\n",
    "            data[i] = 1\n",
    "        else:\n",
    "            data[i] = 0\n",
    "    return data\n",
    "        \n",
    "eeg_data = df.iloc[:, 1:-1].values\n",
    "keypress_data = df.iloc[:, -1].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "eeg_normalized = scaler.fit_transform(eeg_data)\n",
    "\n",
    "seq_length = 100\n",
    "eeg_seq, keystroke_seq = create_sequences(np.hstack((eeg_normalized, keypress_data.reshape(-1,1))), seq_length)\n",
    "\n",
    "eeg_tensor = torch.tensor(eeg_seq, dtype=torch.float32)\n",
    "keystroke_tensor = torch.tensor(keystroke_seq, dtype=torch.float32)\n",
    "\n",
    "eeg_train, eeg_test, keystroke_train, keystroke_test = train_test_split(eeg_tensor, keystroke_tensor, test_size=0.2, random_state=47)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(keystroke_train.numpy()), y=keystroke_train.numpy())\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "#Calculate sample weights\n",
    "samples_weights = class_weights[keystroke_train.long()]\n",
    "sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac020893-644a-46c0-b8e0-385a93a0dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_data = TensorDataset(eeg_train, keystroke_train)\n",
    "test_data = TensorDataset(eeg_test, keystroke_test)\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size, sampler=sampler)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97544d72-8866-4d19-aea1-134f00e82ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fully_connected = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c_init = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (initial, c_init))\n",
    "        out = self.fully_connected(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d002396f-f524-48d4-bcee-f6110cd5a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8 #eeg_train.shape[1]\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 1\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "crit = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1]) #for binary classification\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fa9634b-4901-4b18-943f-9d2d22d46262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features,labels) in enumerate(train_loader):\n",
    "        outputs = model(features)\n",
    "        loss = crit(outputs.squeeze(), labels)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ced7091-26d3-4641-a194-0c8e219ad183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for eeg_batch, shortcut_batch in test_loader:\n",
    "        outputs = model(eeg_batch).squeeze(1)\n",
    "        test_loss += crit(outputs, shortcut_batch.float()).item()\n",
    "        predicted = (outputs > 0).long()\n",
    "        correct += (predicted == shortcut_batch).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = correct / len(test_data)\n",
    "print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'eeg_shortcut_predictor.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a0b5f-7a96-4873-ad99-7bb0925f49df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626fdfa2-f75f-4dd2-8863-f1b219d76945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_env)",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
